---
# ansible-playbook -u root reset.yml -k -e @group_vars/all
- hosts: rhhi
  gather_facts: no
  ignore_errors: yes

  tasks:
  - name: "Clean up hosted-engine"
    command: "/usr/sbin/ovirt-hosted-engine-cleanup -q"
    run_once: yes
    delegate_to: "{{node1_fqdn}}"

  - name: "Stop the Gluster volume"
    gluster_volume: name={{ item }} state=stopped
    run_once: yes
    with_items: [ engine, ssdvmstore, nvmevmstore ]

  - name: "Delete the Gluster volume"
    gluster_volume: name={{ item }} state=absent
    run_once: yes
    with_items: [ engine, ssdvmstore, nvmevmstore ]

  - name: "Remove brick_dirs"
    file: path=/gluster_bricks/{{ item }}/{{ item }}/ state=absent
    with_items: [ engine, ssdvmstore, nvmevmstore ]

  - name: "Unmount the bricks"
    mount: path=/gluster_bricks/{{ item }} state=absent
    with_items: [ engine, ssdvmstore, nvmevmstore ]

  - name: "Dissolve the Trusted Storage Pool"
    command: gluster peer detach {{ item }} --mode=script
    with_items: [ rhhi1-gluster.rnelson-demo.com, rhhi2-gluster.rnelson-demo.com, rhhi3-gluster.rnelson-demo.com ]

  - name: "Remove the VGs"
    command: vgremove {{ item }} --force
    with_items: [ gluster_vg_sda4, gluster_vg_sda5, gluster_vg_nvme0n1 ]

  - name: "Remove the PVs"
    command: pvremove /dev/{{ item }} --force
    with_items: [ sda4, sda5, nvme0n1 ]

  - name: "Wipe the drives"
    command: wipefs -af /dev/{{ item }}
    with_items: [ sda4, sda5, nvme0n1 ]

  - name: "Clean disks the hard way"
    command: dd if=/dev/zero of=/dev/{{ item }} bs=1M count=10
    with_items: [ sda4, sda5, nvme0n1 ]

#  - name: Unregister
#    command: subscription-manager unregister
